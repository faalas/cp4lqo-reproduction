{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queries = ['10b.csv', '10c.csv', '11b.csv', '11c.csv', '11d.csv', '12b.csv', '12c.csv', '13b.csv',\n",
    "#                          '13c.csv', '13d.csv', '14b.csv', '14c.csv', '15b.csv', '15c.csv', '15d.csv', '16b.csv',\n",
    "#                          '16c.csv', '16d.csv', '17b.csv', '17c.csv', '17d.csv', '17e.csv', '17f.csv', '18b.csv',\n",
    "#                          '18c.csv', '19b.csv', '19c.csv', '19d.csv', '1b.csv', '1c.csv', '1d.csv', '20b.csv', '20c.csv',\n",
    "#                          '21b.csv', '21c.csv', '22b.csv', '22c.csv', '22d.csv', '23b.csv', '23c.csv', '24b.csv',\n",
    "#                          '25b.csv', '25c.csv', '26b.csv', '26c.csv', '27b.csv', '27c.csv', '28b.csv', '28c.csv',\n",
    "#                          '29b.csv', '29c.csv', '2b.csv', '2c.csv', '2d.csv', '30b.csv', '30c.csv', '31b.csv', '31c.csv',\n",
    "#                          '32b.csv', '33b.csv', '33c.csv', '3b.csv', '3c.csv', '4b.csv', '4c.csv', '5b.csv', '5c.csv',\n",
    "#                          '6b.csv', '6c.csv', '6d.csv', '6e.csv', '6f.csv', '7b.csv', '7c.csv', '8b.csv', '8c.csv',\n",
    "#                          '8d.csv', '9b.csv', '9c.csv', '9d.csv']\n",
    "# DATA_PATH = \"\" # 80 in total\n",
    "# normalizaton_imdb = 10\n",
    "\n",
    "queries = [\"{}{}.csv\".format(i,x)for i in [5,7,8,10,12,13,14] for x in [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\"]]\n",
    "\n",
    "print(len(queries)) # 70 in total\n",
    "DATA_PATH = \"\"\n",
    "print(DATA_PATH) \n",
    "normalization_tpch=75\n",
    "normalization = normalization_tpch\n",
    "\n",
    "#normalization = normalizaton_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conformal_score_difference(cost, latency):\n",
    "  return abs(cost - latency)\n",
    "\n",
    "def get_conformal_score(conformal_score_lambda, set_name):\n",
    "  all_data = pd.DataFrame()\n",
    "  for query in set_name:\n",
    "      csv_file = DATA_PATH+query\n",
    "      query_id = query.split('.')[0]\n",
    "      try:\n",
    "          df = pd.read_csv(csv_file)\n",
    "          df['ConformalScore'] = conformal_score_lambda(df['Cost']/normalization, df['Actual Total Time'])\n",
    "          df['QueryID'] = query_id\n",
    "          df = df[~df['Operation'].str.contains('Scan')]\n",
    "          df = df.iloc[[0]]\n",
    "          all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "\n",
    "      except FileNotFoundError:\n",
    "          print(f\"File {csv_file} not found.\")\n",
    "      except Exception as e:\n",
    "          print(f\"An error occurred while processing {csv_file}: {e}\")\n",
    "  return list(all_data[\"ConformalScore\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def update_get_quantile(alpha, sortedCP):\n",
    "    n = len(sortedCP)\n",
    "    q_hat_index = math.ceil(((n+1)*(1-alpha)))\n",
    "    return sortedCP[q_hat_index-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_stats(quantList):\n",
    "  # Example list of numbers\n",
    "  numbers = quantList\n",
    "\n",
    "  # Convert the list to a NumPy array\n",
    "  data = np.array(numbers)\n",
    "\n",
    "  # Calculate mean and standard deviation\n",
    "  mean = np.mean(data)\n",
    "  std_dev = np.std(data)\n",
    "\n",
    "  # Plot the data\n",
    "  plt.figure(figsize=(10, 6))\n",
    "\n",
    "  # Plot the numbers\n",
    "  plt.plot(data, marker='o', label='Data')\n",
    "\n",
    "  # Plot the mean line\n",
    "  plt.axhline(mean, color='red', linestyle='--', label=f'Mean: {mean:.2f}')\n",
    "\n",
    "  # Plot lines for 1 standard deviation from the mean\n",
    "  plt.axhline(mean + std_dev, color='green', linestyle='--', label=f'Mean + 1 Std: {mean + std_dev:.2f}')\n",
    "  plt.axhline(mean - std_dev, color='green', linestyle='--', label=f'Mean - 1 Std: {mean - std_dev:.2f}')\n",
    "\n",
    "  # Labels and title\n",
    "  plt.title('Deviation Plot')\n",
    "  plt.xlabel('Index')\n",
    "  plt.ylabel('Value')\n",
    "  plt.legend()\n",
    "\n",
    "  # Show the plot\n",
    "  plt.grid(True)\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offline_verfication(iterations, calibration_set_size, alpha = 0.1):\n",
    "  valid_rates = []\n",
    "  all_quant_vals = []\n",
    "  count_above_90 = 0\n",
    "  for i in range(iterations):\n",
    "    calibration_set = random.sample(queries, calibration_set_size)\n",
    "    test_set = [elem for elem in queries if elem not in calibration_set]\n",
    "\n",
    "    CPScores_cali = get_conformal_score(conformal_score_difference, calibration_set)\n",
    "    sortedCP_cali = sorted(CPScores_cali)\n",
    "    quantVal = update_get_quantile(alpha, sortedCP_cali)\n",
    "    all_quant_vals.append(quantVal)\n",
    "\n",
    "    CPScores_test = get_conformal_score(conformal_score_difference, test_set)\n",
    "    num_in = 0\n",
    "    for val in CPScores_test:\n",
    "      if val <= quantVal:\n",
    "        num_in += 1\n",
    "\n",
    "    valid_rate = num_in / len(CPScores_test)\n",
    "    if valid_rate > (1-alpha):\n",
    "      count_above_90 += 1\n",
    "\n",
    "    print(\"==> Iter {}, count_above/total: {}/{}, quantVal: {}, valid_rate: {:.2f}%\".format(i, num_in, len(CPScores_test), quantVal, valid_rate*100))\n",
    "\n",
    "    valid_rates.append(valid_rate)\n",
    "\n",
    "  assert(len(valid_rates) == iterations)\n",
    "  avg_valid_rate = sum(valid_rates) / len(valid_rates)\n",
    "  print(\"\\nAverage valid_rate: {:.2f}%\".format(avg_valid_rate * 100))\n",
    "  print(f\"Number of valid_rate > {(1-alpha)*100}%: {format(count_above_90)}\")\n",
    "\n",
    "  plt.hist(valid_rates, bins=30, range=(0.5, 1.0), edgecolor='black')\n",
    "  plt.title(\"Histogram of Valid Rate (Lastest online)\")\n",
    "  plt.xlabel(\"Valid Rate\")\n",
    "  plt.ylabel(\"Frequency\")\n",
    "  plt.grid(True)\n",
    "  plt.show()\n",
    "  quantile_stats(all_quant_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_verfication(1000, 35, 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
